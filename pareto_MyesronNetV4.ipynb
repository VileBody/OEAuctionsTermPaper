{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "pareto_MyesronNetV4.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "In the cells below we set a model class, then we loaded pre-trained weights"
      ],
      "metadata": {
        "id": "lxRhpMp8CAwV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#!pip install optuna"
      ],
      "metadata": {
        "id": "dyhbJuXtU6XY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "__nAU1-5cPQb"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from torch import nn, optim\n",
        "import numpy as np\n",
        "import optuna\n",
        "from scipy import stats as ss\n",
        "from matplotlib import pyplot as plt\n",
        "from IPython.display import clear_output"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from random import random\n",
        "class Generator:\n",
        "  def __init__(self, n_bidders, batch_size, dist, params={}):\n",
        "    self.n_bidders = n_bidders\n",
        "    self.batch_size = batch_size\n",
        "    self.dist = dist\n",
        "    self.params = params \n",
        "\n",
        "  def generate(self, seed=np.random.randint(1, 15000)):\n",
        "    if self.dist == 'irregular':\n",
        "      probs, params, dist_name = self.params['probs'], self.params['params'], self.params['dist_name']\n",
        "      gen = lambda x: dist_name.rvs(**x)\n",
        "      gen = np.vectorize(gen)\n",
        "      dist_matrix = np.random.choice(params, size=(self.batch_size, self.n_bidders), p=probs)\n",
        "      sample_val = np.array(list(map(gen, dist_matrix)))\n",
        "      return torch.tensor(sample_val, dtype=torch.float)\n",
        "\n",
        "    return torch.tensor(\n",
        "        self.dist.rvs(size=(self.batch_size, self.n_bidders), random_state=seed, **self.params), dtype=torch.float\n",
        "    )"
      ],
      "metadata": {
        "id": "lDNahNyoccmP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class MyersonNetV4(nn.Module):\n",
        "    def __init__(self, n_bidders, J_functions=10, K_groups=10, B=1.0, softmax_temperature=1.0):\n",
        "      super(MyersonNetV4, self).__init__()\n",
        "      self.J, self.K, self.B, self.kappa, self.n_bidders = J_functions, K_groups, B, softmax_temperature, n_bidders\n",
        "      self.w_transformation = nn.Sequential(\n",
        "          nn.Linear(self.n_bidders, self.J * self.K),\n",
        "          nn.ReLU(),\n",
        "          nn.Linear(self.J * self.K, self.J * self.K),\n",
        "          nn.ReLU(),\n",
        "          nn.Linear(self.J * self.K, self.J * self.K),\n",
        "      )\n",
        "      self.b_transformation = nn.Sequential(\n",
        "          nn.Linear(self.n_bidders, self.J * self.K),\n",
        "          nn.ReLU(),\n",
        "          nn.Linear(self.J * self.K, self.J * self.K),\n",
        "          nn.ReLU(),\n",
        "          nn.Linear(self.J * self.K, self.J * self.K),\n",
        "      )\n",
        "      self.device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "      self.mask = torch.ones([self.n_bidders, 1, self.n_bidders]).to(self.device)\n",
        "      self.mask[np.arange(self.n_bidders), :, np.arange(self.n_bidders)] = 0.\n",
        "\n",
        "      \n",
        "    def transform_weights(self, data):\n",
        "      w = self.w_transformation(data).view(self.J, self.K, -1, 1)\n",
        "      bias = self.b_transformation(data).view(self.J, self.K, -1, 1)\n",
        "      return (w, bias)#torch.clamp(self.w, -self.B, self.B)\n",
        "    \n",
        "    def get_virtual_valuation(self, data, weights):\n",
        "      weights, bias = weights\n",
        "      return torch.min(\n",
        "          torch.max(torch.exp(weights) * data + bias, axis=0).values,\n",
        "          axis=0\n",
        "      ).values\n",
        "\n",
        "    def get_inverse_virtual_valuation(self, phi, weights):\n",
        "      weights, bias = weights\n",
        "      return torch.max(\n",
        "          torch.min(torch.exp(-weights) * (phi - bias), axis=0).values,\n",
        "          axis=0\n",
        "      ).values\n",
        "\n",
        "    def get_allocation(self, array, task):\n",
        "        mask = torch.ones(array.shape[1]+1).to(self.device)\n",
        "        mask[-1] = 0.\n",
        "        mask = torch.diag(mask)[:-1, :]\n",
        "        if task == 'train':\n",
        "          return torch.nn.functional.softmax(array @ (self.kappa * mask), dim=-1)[:, :-1]\n",
        "        elif task == 'eval':\n",
        "          return torch.nn.functional.softmax(array @ (1e25 * mask), dim=-1)[:, :-1]\n",
        "        else:\n",
        "          raise ValueError('Wrong task, choose among \"train\", \"eval\".')\n",
        "        \n",
        "\n",
        "    def get_payment(self, phi, weights):\n",
        "      second_price = torch.max(self.mask * phi, axis=-1).values.swapaxes(0, 1)\n",
        "      payment = self.get_inverse_virtual_valuation(second_price, weights)\n",
        "      return payment\n",
        "\n",
        "    def forward(self, data, task='train'):\n",
        "      weights = self.transform_weights(data)\n",
        "      phi = self.get_virtual_valuation(data, weights)\n",
        "      allocation = self.get_allocation(phi, task) \n",
        "      payment = self.get_payment(phi, weights)\n",
        "      return - torch.mean(\n",
        "          torch.sum(allocation * payment, axis=1)\n",
        "      ), (payment, allocation, data, phi)"
      ],
      "metadata": {
        "id": "WqNlhKN-R2qo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def define_model(trial):\n",
        "  device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "  n_bidders, J_functions, K_groups, B, softmax_temperature, batch_size = 3, 15, 33, 8, 1e2, 128\n",
        "  softmax_temperature = 1e2#trial.suggest_float('softmax_t', 1., 3e3)\n",
        "  model = MyersonNetV4(n_bidders, J_functions=J_functions, K_groups=K_groups, B=B, softmax_temperature=softmax_temperature).to(device)\n",
        "  model.load_state_dict(torch.load('/content/model_at_iter_6800_15_33.pickle'))\n",
        "  learning_rate = trial.suggest_float('learning_rate', 1e-8, 1e-2)\n",
        "  learning_rate_lambdas = trial.suggest_float('learning_rate_lambdas', 1e-8, 1e-2)\n",
        "  lambdas = nn.ParameterList([nn.Parameter(torch.ones(size=(1, )) * trial.suggest_float('lambdas', -5., 5.))]).to(device)\n",
        "  optim_lambdas = optim.Adam(lambdas.parameters(), lr=learning_rate)\n",
        "  optimizer = optim.Adam(model.parameters(), lr=learning_rate_lambdas)\n",
        "  c = trial.suggest_float('c', 0.5, 10.)\n",
        "  j_iter = trial.suggest_int('j_iter', 100, 500)\n",
        "  step_size = trial.suggest_float('step_size', 1e-5, 1e-2)\n",
        "  return model, optimizer, lambdas, optim_lambdas, c, j_iter, step_size"
      ],
      "metadata": {
        "id": "FpZf856cPQKD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train_model(model, optimizer, lambdas, optim_lambdas, c, j_iter, step_size, generators):\n",
        "  device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "  losses, revenues, utilities, gap = [], [], [], []\n",
        "  batch = torch.cat([generator.generate() for generator in generators])[torch.randperm(1280)].to(device)\n",
        "  neg_revenue, (payment, allocation, data, phi) = model(batch)\n",
        "  max_revenue = - neg_revenue.detach()\n",
        "  for i in range(0, 150):\n",
        "    factor = (1 - step_size) ** i\n",
        "    lower_bound = (factor * max_revenue).detach()\n",
        "    for j in range(j_iter):\n",
        "      optim_lambdas.zero_grad()\n",
        "      optimizer.zero_grad()\n",
        "      neg_revenue, (payment, allocation, data, phi) = model(batch)\n",
        "      if payment.sum().isnan() or allocation.sum().isnan():\n",
        "        break\n",
        "      revenue = - neg_revenue\n",
        "      utility = torch.mean(torch.sum((data - payment) * allocation, dim=-1))\n",
        "      loss = - utility + lambdas[0] * (\n",
        "          revenue - lower_bound\n",
        "      ) + c/2 * (revenue - lower_bound) ** 2\n",
        "\n",
        "      loss.backward()\n",
        "      lambdas[0].grad = - lambdas[0].grad\n",
        "      optim_lambdas.step()\n",
        "      optimizer.step()\n",
        "    losses.append( loss.detach().cpu().numpy().item())\n",
        "    revenues.append( -revenue.detach().cpu().numpy().item())\n",
        "    utilities.append( -utility.detach().cpu().numpy().item())\n",
        "    gap.append((revenue - lower_bound).mean().cpu().detach().numpy().item())\n",
        "\n",
        "  return [np.array(x) for x in (losses, revenues, utilities, gap)]\n",
        "\n",
        "from scipy.optimize import curve_fit\n",
        "from sklearn.metrics import mean_absolute_percentage_error as mape\n",
        "\n",
        "def polynom(x, a, b, c):\n",
        "  return a * x ** 2 + b * x + c\n",
        "\n",
        "def compute_metrics(logs, step_size):\n",
        "  losses, revenues, utilities, gap = logs\n",
        "  smoothness_f = lambda x: np.std(np.diff(x))/np.abs(np.mean(np.diff(x)))\n",
        "  gap_sum_abs = np.mean(np.abs(gap))\n",
        "  x = np.array([(1 - step_size) ** i for i in range(150)])\n",
        "  try:\n",
        "    coefs, someshit = curve_fit(polynom, utilities[:], revenues[:])\n",
        "    f = interp1d(utilities, revenues)\n",
        "    x = np.linspace(utilities.min(), utilities.max(), 1000)\n",
        "    smoothness = mape(f(x), polynom(f(x), *coefs))\n",
        "    res = [utilities[~np.isnan(utilities)].mean(), smoothness, gap_sum_abs, np.isnan(utilities).sum(), -len(set(utilities))]\n",
        "  except:\n",
        "    return [utilities[~np.isnan(utilities)].mean(), 99999, gap_sum_abs, np.isnan(utilities).sum(), -len(set(utilities))]\n",
        "  \n",
        "  return res\n",
        "\n"
      ],
      "metadata": {
        "id": "7bFCnPoGLjyA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def objective(trial):\n",
        "  params_all = []\n",
        "  for right_border in np.linspace(0, 30, 10):\n",
        "    params = dict()\n",
        "    params['probs'] = [0.75, 0.25]\n",
        "    params['params'] = [{'loc': 0, 'scale': 3}, {'loc': 3, 'scale': right_border}]\n",
        "    params['dist_name'] = ss.uniform\n",
        "    params_all.append(params)\n",
        "  generators = [Generator(3, 128, 'irregular', params) for params in params_all]\n",
        "  model, optimizer, lambdas, optim_lambdas, c, j_iter, step_size = define_model(trial)\n",
        "  logs = train_model(model, optimizer, lambdas, optim_lambdas, c, j_iter, step_size, generators)\n",
        "  metrics = compute_metrics(logs, step_size)\n",
        "    \n",
        "  return metrics"
      ],
      "metadata": {
        "id": "RXIcXB-xPW-f"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "study = optuna.create_study(directions=['minimize' for i in range(5)] )\n",
        "fig = plt.figure(figsize=(10, 3))\n",
        "study.optimize(objective, n_trials=300)\n",
        "\n",
        "print(\"Number of finished trials: \", len(study.trials))"
      ],
      "metadata": {
        "id": "F6mQvT5hVHM_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "best_numbers = [x.number for x in study.best_trials]\n",
        "data = study.trials_dataframe()\n",
        "data['number_isin_best_numbers'] = datap['number'].isin(best_numbers)"
      ],
      "metadata": {
        "id": "CFWT3OJY8wV_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Not the best option but we chose an appropriate configuration for the model manually"
      ],
      "metadata": {
        "id": "WJf433B7CO4y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "params = data[data['number_isin_best_numbers']].iloc[:, 7:-4].loc[208]"
      ],
      "metadata": {
        "id": "m9CgFlsqv4jZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "best_params = params.to_dict()"
      ],
      "metadata": {
        "id": "dnod4zZTwPgh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def define_model_eval(params):\n",
        "  device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "  n_bidders, J_functions, K_groups, B, softmax_temperature, batch_size = 3, 10, 5, 8, 1e2, 128\n",
        "  softmax_temperature = 1e3\n",
        "  model = MyersonNetV4(n_bidders, J_functions=J_functions, K_groups=K_groups, B=B, softmax_temperature=softmax_temperature).to(device)\n",
        "  model.load_state_dict(torch.load('/content/model_at_iter_6150.pickle'))\n",
        "  learning_rate = params['params_learning_rate']\n",
        "  learning_rate_lambdas = params['params_learning_rate_lambdas']\n",
        "  lambdas = nn.ParameterList([nn.Parameter(torch.ones(size=(1, )) * params['params_lambdas'])]).to(device)\n",
        "  optim_lambdas = optim.Adam(lambdas.parameters(), lr=learning_rate)\n",
        "  optimizer = optim.Adam(model.parameters(), lr=learning_rate_lambdas)\n",
        "  c = params['params_c']\n",
        "  j_iter = params['params_j_iter']\n",
        "  step_size = params['params_step_size']\n",
        "  return model, optimizer, lambdas, optim_lambdas, c, j_iter, step_size\n",
        "params_all = []\n",
        "for right_border in np.linspace(0, 30, 10):\n",
        "  params = dict()\n",
        "  params['probs'] = [0.75, 0.25]\n",
        "  params['params'] = [{'loc': 0, 'scale': 3}, {'loc': 3, 'scale': right_border}]\n",
        "  params['dist_name'] = ss.uniform\n",
        "  params_all.append(params)\n",
        "generators = [Generator(3, 128, 'irregular', params) for params in params_all]\n",
        "model, optimizer, lambdas, optim_lambdas, c, j_iter, step_size = define_model_eval(best_params)\n",
        "logs = train_model(model, optimizer, lambdas, optim_lambdas, c, j_iter, step_size, generators)"
      ],
      "metadata": {
        "id": "10iDepKod7uV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "losses, revenues, utilities, gap = logs"
      ],
      "metadata": {
        "id": "Cj4UDjvydnz3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.scatter(-utilities, -revenues)"
      ],
      "metadata": {
        "id": "qcIJnc8tex_3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.plot(-utiliiess)"
      ],
      "metadata": {
        "id": "YT9h7UqJfJIj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.plot(-revenues)"
      ],
      "metadata": {
        "id": "5dSdMCogxGt3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.plot(gap)"
      ],
      "metadata": {
        "id": "06mNRj5oe5ax"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}