{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import time\nimport json\nfrom collections import defaultdict\n\nimport numpy as np\nimport torch\nfrom torch import nn, tensor, optim\nfrom torch.utils.tensorboard import SummaryWriter\nfrom torch.nn import functional as F\n\nfrom regretnet.plot import plot\n\nclass Trainer(object):\n    def __init__(self, configuration, net, clip_op_lambda, device):\n        self.net = net\n        self.config = configuration\n        self.device = device\n        self.mode = 'train'\n        self.clip_op_lambda = clip_op_lambda\n\n        #self.writer = SummaryWriter(self.config.save_data)\n\n        self.init_componenents()\n\n    def init_componenents(self):\n        self.create_constants()\n\n        self.create_params_to_train()\n\n        self.create_optimizers()\n\n        self.create_masks()\n\n        #self.save_config()\n\n    def create_constants(self):\n        self.x_shape = dict()\n        self.x_shape['train'] = [self.config.train.batch_size, self.config.num_agents, self.config.num_items]\n        self.x_shape['val'] = [self.config.val.batch_size, self.config.num_agents, self.config.num_items]\n\n        self.adv_shape = dict()\n        self.adv_shape['train'] = [self.config.num_agents, self.config.train.num_misreports,\n                                   self.config.train.batch_size, self.config.num_agents, self.config.num_items]\n        self.adv_shape['val'] = [self.config.num_agents, self.config.val.num_misreports,\n                                 self.config.val.batch_size, self.config.num_agents, self.config.num_items]\n\n        self.adv_var_shape = dict()\n        self.adv_var_shape['train'] = [self.config.train.num_misreports, self.config.train.batch_size,\n                                       self.config.num_agents, self.config.num_items]\n        self.adv_var_shape['val'] = [self.config.val.num_misreports, self.config.val.batch_size,\n                                     self.config.num_agents, self.config.num_items]\n\n        self.u_shape = dict()\n        self.u_shape['train'] = [self.config.num_agents, self.config.train.num_misreports,\n                                 self.config.train.batch_size, self.config.num_agents]\n        self.u_shape['val'] = [self.config.num_agents, self.config.val.num_misreports,\n                               self.config.val.batch_size, self.config.num_agents]\n\n        self.w_rgt = self.config.train.w_rgt_init_val\n        self.w_rev = 5e3\n        self.rgt_target = self.config.train.rgt_target_start\n        self.rgt_target_mult = (self.config.train.rgt_target_end / self.config.train.rgt_target_start) ** \\\n                               (1.5 / self.config.train.max_iter)\n\n    def create_params_to_train(self, train=True, val=True):\n        # Trainable variable for find best misreport using gradient by inputs\n        self.adv_var = dict()\n        if train: self.adv_var['train'] = torch.zeros(self.adv_var_shape['train'], requires_grad=True,\n                                                      device=self.device).float()\n        if val: self.adv_var['val'] = torch.zeros(self.adv_var_shape['val'], requires_grad=True,\n                                                  device=self.device).float()\n\n    def create_optimizers(self, train=True, val=True):\n        self.opt1 = optim.Adam(self.net.parameters(), self.config.train.learning_rate)\n\n        # Optimizer for best misreport find\n        self.opt2 = dict()\n        if train: self.opt2['train'] = optim.Adam([self.adv_var['train']], self.config.train.gd_lr)\n        if val: self.opt2['val'] = optim.Adam([self.adv_var['val']], self.config.val.gd_lr)\n\n        self.sc_opt2 = dict()\n        if train: self.sc_opt2['train'] = optim.lr_scheduler.StepLR(self.opt2['train'], 1, self.config.train.gd_lr_step)\n        if val: self.sc_opt2['val'] = optim.lr_scheduler.StepLR(self.opt2['val'], 1, self.config.val.gd_lr_step)\n\n    def create_masks(self, train=True, val=True):\n        self.adv_mask = dict()\n        if train:\n            self.adv_mask['train'] = np.zeros(self.adv_shape['train'])\n            self.adv_mask['train'][np.arange(self.config.num_agents), :, :, np.arange(self.config.num_agents), :] = 1.0\n            self.adv_mask['train'] = tensor(self.adv_mask['train']).float()\n\n        if val:\n            self.adv_mask['val'] = np.zeros(self.adv_shape['val'])\n            self.adv_mask['val'][np.arange(self.config.num_agents), :, :, np.arange(self.config.num_agents), :] = 1.0\n            self.adv_mask['val'] = tensor(self.adv_mask['val']).float()\n\n        self.u_mask = dict()\n        if train:\n            self.u_mask['train'] = np.zeros(self.u_shape['train'])\n            self.u_mask['train'][np.arange(self.config.num_agents), :, :, np.arange(self.config.num_agents)] = 1.0\n            self.u_mask['train'] = tensor(self.u_mask['train']).float()\n\n        if val:\n            self.u_mask['val'] = np.zeros(self.u_shape['val'])\n            self.u_mask['val'][np.arange(self.config.num_agents), :, :, np.arange(self.config.num_agents)] = 1.0\n            self.u_mask['val'] = tensor(self.u_mask['val']).float()\n\n    def save_config(self):\n        with open(self.writer.log_dir + '/config.json', 'w') as f:\n            json.dump(self.config, f)\n\n    def mis_step(self, x):\n        '''\n        Find best misreport step using gradient by inputs, trainable inputs: self.adv_var variable\n        '''\n        mode = self.mode\n\n        self.opt2[mode].zero_grad()\n\n        # Get misreports\n        x_mis, misreports = self.get_misreports_grad(x)\n\n        # Run net for misreports\n        a_mis, p_mis = self.net(misreports)\n\n        # Calculate utility\n        utility_mis = self.compute_utility(x_mis, a_mis, p_mis)\n\n        # Calculate loss value\n        u_mis = - (utility_mis.view(self.u_shape[mode]) * self.u_mask[mode].to(self.device)).sum()\n\n        # Make a step\n        u_mis.backward()\n        self.opt2[mode].step()\n        self.sc_opt2[mode].step()\n\n    def train_op(self, x):\n        '''\n        Loss for main net train\n        '''\n        self.opt1.zero_grad()\n\n        x_mis, misreports = self.get_misreports(x)\n        alloc_true, pay_true = self.net(x)\n        a_mis, p_mis = self.net(misreports)\n\n        rgt, utility = self.compute_regret(x, alloc_true, pay_true, x_mis, a_mis, p_mis)\n        rgt = rgt.sum()\n        utility = utility.mean()\n        # Revenue\n        revenue = self.compute_rev(pay_true)\n\n        # Dual gradient decent\n        self.w_rgt = max(0, self.w_rgt + self.config.train.rgt_lr *\n                         #maybe this detach is needed to allow for backward\n                         ((rgt / (revenue + 1e-8)).detach().log().item() - np.log(self.rgt_target)))\n        self.w_rev = max(0, self.w_rev + self.config.train.revenue_lr *\n                         (revenue).detach().item() - self.alpha * self.revenue_max)\n\n        final_loss = -utility + self.w_rgt * rgt + self.w_rev * revenue\n\n        # Make a step\n        final_loss.backward()\n        nn.utils.clip_grad_norm_(self.net.parameters(), 1)\n        self.opt1.step()\n\n        return final_loss, revenue, rgt, utility, (revenue).detach().item() - self.alpha * self.revenue_max\n\n    def compute_metrics(self, x):\n        '''\n        Validation metrics\n        '''\n        x_mis, misreports = self.get_misreports_grad(x)\n\n        alloc_true, pay_true = self.net(x)\n        a_mis, p_mis = self.net(misreports)\n\n        rgt = self.compute_regret_grad(x, alloc_true, pay_true, x_mis, a_mis, p_mis)\n\n        revenue = self.compute_rev(pay_true)\n\n        return revenue, rgt.mean()\n\n    def compute_rev(self, pay):\n        \"\"\" Given payment (pay), computes revenue\n            Input params:\n                pay: [num_batches, num_agents]\n            Output params:\n                revenue: scalar\n        \"\"\"\n        return pay.sum(dim=-1).mean()\n\n    def compute_utility(self, x, alloc, pay):\n        \"\"\" Given input valuation (x), payment (pay) and allocation (alloc), computes utility\n            Input params:\n                x: [num_batches, num_agents, num_items]\n                a: [num_batches, num_agents, num_items]\n                p: [num_batches, num_agents]\n            Output params:\n                utility: [num_batches, num_agents]\n        \"\"\"\n        return (alloc * x).sum(dim=-1) - pay\n\n    def compute_regret(self, x, a_true, p_true, x_mis, a_mis, p_mis):\n        return self.compute_regret_grad(x, a_true, p_true, x_mis, a_mis, p_mis)\n\n    def compute_regret_grad(self, x, a_true, p_true, x_mis, a_mis, p_mis):\n        mode = self.mode\n\n        utility = self.compute_utility(x, a_true, p_true)\n        utility_mis = self.compute_utility(x_mis, a_mis, p_mis)\n\n        utility_true = utility.repeat(self.config.num_agents * self.config[mode].num_misreports, 1)\n        excess_from_utility = F.relu((utility_mis - utility_true).view(self.u_shape[mode]) *\n                                     self.u_mask[mode].to(self.device))\n\n        rgt = excess_from_utility.max(3)[0].max(1)[0].mean(dim=1)\n        return rgt, utility\n\n    def get_misreports(self, x):\n        return self.get_misreports_grad(x)\n\n    def get_misreports_grad(self, x):\n        mode = self.mode\n        adv_mask = self.adv_mask[mode].to(self.device)\n\n        adv = self.adv_var[mode].unsqueeze(0).repeat(self.config.num_agents, 1, 1, 1, 1)\n        x_mis = x.repeat(self.config.num_agents * self.config[mode].num_misreports, 1, 1)\n        x_r = x_mis.view(self.adv_shape[mode])\n        y = x_r * (1 - adv_mask) + adv * adv_mask\n        misreports = y.view([-1, self.config.num_agents, self.config.num_items])\n        return x_mis, misreports\n\n    def train(self, generator):\n        '''\n        Main function, full train process\n        '''\n        # Make a generators for train and validation\n        self.train_gen, self.val_gen = generator\n\n        iteration = self.config.train.restore_iter\n\n        # Load save model\n        if iteration > 0:\n            model_path = self.writer.log_dir + '/model_{}'.format(iteration)\n            state_dict = torch.load(model_path)\n            self.net.load_state_dict(state_dict)\n\n        time_elapsed = 0.0\n\n        while iteration < (self.config.train.max_iter):\n            tic = time.time()\n            self.train_epoch(iteration)\n\n            toc = time.time()\n            time_elapsed += (toc - tic)\n\n            iteration += 1\n            self.writer.add_scalar('Train/epoch time', time_elapsed, iteration / 1000)\n\n            if (iteration + 1) % self.config.train.save_iter == 0:\n                self.save(iteration + 1)\n\n            # Validation\n            if (iteration % self.config.val.print_iter) == 0:\n                self.eval(iteration)\n\n    def train_epoch(self, iteration):\n        self.mode = 'train'\n        self.net.train()\n\n        # Get new batch. X - true valuation, ADV - start point for misreport candidates\n        # perm - ADV positions in full train dataset\n        X, ADV, perm = next(self.train_gen.gen_func)\n\n        x = torch.from_numpy(X).float().to(self.device)\n\n        # Write start adv value for find best misreport variable\n        self.adv_var['train'].data = tensor(ADV).float().to(self.device)\n\n        self.misreport_cycle(x)\n\n        # Save found best misreport values in data generator\n        if self.config.train.data is 'fixed' and self.config.train.adv_reuse:\n            self.train_gen.update_adv(perm, self.adv_var['train'].data.cpu())\n\n        # Make a step for net weights updating\n        net_loss, train_revenue, train_regret = self.train_op(x)\n\n        self.rgt_target = max(self.rgt_target * self.rgt_target_mult, self.config.train.rgt_target_end)\n\n        if (iteration % self.config.train.print_iter) == 0:\n            print('Iteration {}'.format(iteration))\n            print('Train revenue: {},   regret: {},   net loss: {} , w: {}'.format(\n                round(float(train_revenue), 5),\n                round(float(train_regret), 5),\n                round(float(net_loss), 5),\n                round(self.w_rgt, 4)\n            ))\n            self.writer.add_scalar('Train/revenue', train_revenue, iteration / 1000)\n            self.writer.add_scalar('Train/regret', train_regret, iteration / 1000)\n            self.writer.add_scalar('Train/loss', net_loss, iteration / 1000)\n            self.writer.add_scalar('Train/w_rgt', self.w_rgt, iteration / 1000)\n\n    def eval(self, iteration):\n        print('Validation on {} iteration'.format(iteration))\n        self.mode = 'val'\n        self.net.eval()\n\n        self.eval_grad(iteration)\n\n        if self.config.plot.bool:\n            self.plot()\n\n    def eval_grad(self, iteration):\n        val_revenue = 0\n        val_regret = 0\n\n        for _ in range(self.config.val.num_batches):\n            X, ADV, _ = next(self.val_gen.gen_func)\n            self.adv_var['val'].data = tensor(ADV).float().to(self.device)\n\n            x = torch.from_numpy(X).float().to(self.device)\n\n            self.misreport_cycle(x)\n\n            val_revenue_batch, val_regret_batch = self.compute_metrics(x)\n            val_revenue += val_revenue_batch\n            val_regret += val_regret_batch\n\n        val_revenue /= float(self.config.val.num_batches)\n        val_regret /= float(self.config.val.num_batches)\n\n        print('Val revenue: {},   regret_grad: {}'.format(\n            round(float(val_revenue), 5),\n            round(float(val_regret), 5)))\n        self.writer.add_scalar('Validation/revenue', val_revenue, iteration / 1000)\n        self.writer.add_scalar('Validation/regret_grad', val_regret, iteration / 1000)\n\n    def plot(self):\n        x = np.linspace(self.config.min, self.config.max, self.config.plot.n_points)\n        x = np.stack([v.flatten() for v in np.meshgrid(x, x)], axis=-1)\n        x = np.expand_dims(x, 1)\n        x = torch.FloatTensor(x)\n\n        allocation, _ = self.net(x)\n        allocation = allocation.detach().numpy()[:, 0, :].reshape(self.config.plot.n_points, self.config.plot.n_points,\n                                                                  self.config.num_items)\n\n        plot(allocation, self.config.dir_name, self.config.setting)\n\n    def misreport_cycle(self, x):\n        mode = self.mode\n\n        # Find best misreport cycle\n        for _ in range(self.config[mode].gd_iter):\n            # Make a gradient step, update self.adv_var variable\n            self.mis_step(x)\n\n            # Clipping new values of self.adv_var with respect for valuations distribution\n            self.adv_var[mode].data.clamp_(self.config.min, self.config.max)\n\n        for param_group in self.opt2[mode].param_groups:\n            param_group['lr'] = self.config[mode].gd_lr\n\n        self.opt2[mode].state = defaultdict(dict)  # reset momentum\n\n    def save(self, iteration):\n        torch.save(self.net.state_dict(), self.writer.log_dir + '/model_{}'.format(iteration))\n","metadata":{"id":"kNtAOiu4H-tK","execution":{"iopub.status.busy":"2022-06-06T20:16:56.296823Z","iopub.execute_input":"2022-06-06T20:16:56.297186Z","iopub.status.idle":"2022-06-06T20:16:56.370086Z","shell.execute_reply.started":"2022-06-06T20:16:56.297155Z","shell.execute_reply":"2022-06-06T20:16:56.369267Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Source: [Optimal-er Auctions through Attention - arXiv](https://arxiv.org/pdf/2202.13110.pdf)","metadata":{}},{"cell_type":"code","source":"import os\nos.chdir('../input/amd-master/amd-master')\nfrom regretnet.utils import get_objects\n#from regretnet.trainer.trainer import Trainer, PartTrainer\nfrom regretnet.nets.additive_net import AdditiveNet\nfrom regretnet.nets.additive_net_attention import AdditiveNetAttention\nfrom regretnet.nets.additive_net_exchangeable import AdditiveNetExchangeable\nfrom regretnet.nets.part_net_attention import PartNetAttention\nfrom regretnet.nets.part_net import PartNet\n\n# os.environ['CUDA_DEVICE_ORDER']='PCI_BUS_ID'\n# os.environ['CUDA_VISIBLE_DEVICES']='1'\n\nsetting = 'additive_3x10_uniform'\n\ndef count_parameters(model):\n    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n\n\n\ndevice = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n\ncfg, _, Generator, clip_op_lambda = get_objects(setting)\ncfg.setting = setting\nif cfg.architecture == 'standard':\n    net2 = AdditiveNet(cfg, device).to(device)\nelif cfg.architecture == 'attention':\n    net2 = AdditiveNetAttention(cfg, device).to(device)\nelif cfg.architecture == 'exchangeable':\n    net2 = AdditiveNetExchangeable(cfg, device).to(device)\nprint('number of parameters, net2 =', count_parameters(net2))\ngenerator = [Generator(cfg, 'train'), Generator(cfg, 'val')]\n\nif cfg.regret_type == 'standard':\n    m = Trainer(cfg, net2, clip_op_lambda, device)\nelif cfg.regret_type == 'part':\n    if cfg.architecture == 'standard':\n        part_net = PartNet(cfg, device).to(device)\n    elif cfg.architecture == 'attention':\n        part_net = PartNetAttention(cfg, device).to(device)\n    print('number of parameters, part_net =', count_parameters(part_net))\n    m = PartTrainer(cfg, net2, part_net, clip_op_lambda, device)\n\nos.chdir('..')\nos.chdir('..')\n","metadata":{"id":"fz6T9yl7e2BN","outputId":"5397eb9a-233f-4605-cc87-13692e7bab25","execution":{"iopub.status.busy":"2022-06-06T20:17:04.588536Z","iopub.execute_input":"2022-06-06T20:17:04.589081Z","iopub.status.idle":"2022-06-06T20:17:05.054603Z","shell.execute_reply.started":"2022-06-06T20:17:04.589038Z","shell.execute_reply":"2022-06-06T20:17:05.053804Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"checkpoint = torch.load(PATH)\nnet2.load_state_dict(checkpoint)","metadata":{"id":"-TbTtA3cL2A6","outputId":"96704400-e13c-48a3-964e-ebe251ba35f2","execution":{"iopub.status.busy":"2022-06-06T20:18:25.653754Z","iopub.execute_input":"2022-06-06T20:18:25.654165Z","iopub.status.idle":"2022-06-06T20:18:25.67021Z","shell.execute_reply.started":"2022-06-06T20:18:25.654129Z","shell.execute_reply":"2022-06-06T20:18:25.669373Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from itertools import chain\nclass WrapperNet(nn.Module):\n  def __init__(self, model, num_unfreezed_parameters, num_units, num_hidden):\n    super(WrapperNet, self).__init__()\n    self.num_unfreezed_parameters, self.num_units, self.num_hidden = num_unfreezed_parameters, num_units, num_hidden\n    self.model = model\n    self.redistribution = nn.Sequential(\n        nn.Linear(self.model.num_agents, self.num_units),\n        nn.ReLU(),\n        *list(chain.from_iterable([[nn.Linear(self.num_units, self.num_units),\n        nn.ReLU()] for i in range(self.num_hidden)])),\n        nn.Linear(self.num_units, self.model.num_agents),\n    )\n    self.reallocation = nn.Sequential(\n        nn.Linear(self.model.num_agents * self.model.num_items, self.num_units),\n        nn.ReLU(),\n        *list(chain.from_iterable([[nn.Linear(self.num_units, self.num_units),\n        nn.ReLU()] for i in range(self.num_hidden)])),\n        nn.Linear(self.num_units, self.model.num_agents * self.model.num_items),\n    )\n\n    for param in net2.named_parameters():\n      if int(param[0].split('.')[1]) <= 5 - self.num_unfreezed_parameters:\n        param[1].requires_grad = False\n      else:\n        param[1].requires_grad = True\n\n  def forward(self, x):\n    alloc_true, pay_true = self.model(x)\n    alloc_true = alloc_true.view(-1, self.model.num_agents * self.model.num_items)\n    alloc_reallocated = self.reallocation(alloc_true).view(-1, self.model.num_agents, self.model.num_items)\n    payment_redistributed = self.redistribution(pay_true)\n    return alloc_reallocated, payment_redistributed","metadata":{"id":"bvdb9iq2ixEE","execution":{"iopub.status.busy":"2022-06-06T20:18:31.930982Z","iopub.execute_input":"2022-06-06T20:18:31.931322Z","iopub.status.idle":"2022-06-06T20:18:31.948747Z","shell.execute_reply.started":"2022-06-06T20:18:31.931293Z","shell.execute_reply":"2022-06-06T20:18:31.947953Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#!pip install optuna\nimport optuna","metadata":{"id":"61WiKuVZukWx","outputId":"0db5f3ba-ed47-4ede-9a1b-e50d400e18f0","execution":{"iopub.status.busy":"2022-06-06T20:18:39.072264Z","iopub.execute_input":"2022-06-06T20:18:39.072801Z","iopub.status.idle":"2022-06-06T20:18:39.965486Z","shell.execute_reply.started":"2022-06-06T20:18:39.072759Z","shell.execute_reply":"2022-06-06T20:18:39.964571Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"cfg.train.revenue_lr = 1e-1\ncfg.train.rgt_lr = 1e-2\ncfg.train.batch_size = 1 * 1024\ncfg.train.learning_rate = 1e-7\ncfg.train.w_rgt_init_val = 42.9537\nm.revenue_max = 5.61554\nm.train_gen, m.val_gen = generator\nG = 500","metadata":{"id":"JBgWbtxyKMOj","execution":{"iopub.status.busy":"2022-06-06T20:19:40.258407Z","iopub.execute_input":"2022-06-06T20:19:40.259067Z","iopub.status.idle":"2022-06-06T20:19:40.264717Z","shell.execute_reply.started":"2022-06-06T20:19:40.259034Z","shell.execute_reply":"2022-06-06T20:19:40.26361Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def assemble_model(trial):\n  device = 'cuda' if torch.cuda.is_available() else 'cpu'\n  checkpoint = torch.load('../input/pretrained-rgtdinet/additive_net_3_10.pickle')\n  net2.load_state_dict(checkpoint)\n  num_unfreezed_parameters = trial.suggest_int('num_unfreezed_parameters', 0, 3)\n  num_units = trial.suggest_int('num_units', 8, 128)\n  num_hidden = trial.suggest_int('num_hid', 2, 6)\n  model = WrapperNet(net2, num_unfreezed_parameters, num_units, num_hidden).to(device)\n  cfg.train.revenue_lr = trial.suggest_float('revenue_lr', 1e-7, 1e-2)\n  cfg.train.rgt_lr = trial.suggest_float('rgt_lr', 1e-7, 1e-2)\n  cfg.train.batch_size = 1024\n  cfg.train.learning_rate = trial.suggest_float('learning_rate', 1e-7, 1e-2)\n  cfg.train.w_rgt_val = 42.9537\n  m = Trainer(cfg, model, clip_op_lambda, device)\n  m.revenue_max = 5.61554\n  m.train_gen, m.val_gen = generator\n  return model","metadata":{"id":"FBUMw7Uxpmn-","execution":{"iopub.status.busy":"2022-06-06T20:19:28.205168Z","iopub.execute_input":"2022-06-06T20:19:28.205607Z","iopub.status.idle":"2022-06-06T20:19:28.218837Z","shell.execute_reply.started":"2022-06-06T20:19:28.205568Z","shell.execute_reply":"2022-06-06T20:19:28.217777Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from scipy.optimize import curve_fit\nfrom sklearn.metrics import mean_absolute_percentage_error as mape\nfrom scipy.interpolate import interp1d\n\n\ndef objective(trial):\n  model = assemble_model(trial)\n  revenues, utilitys, gap, rgts = [], [], [], []\n  G = trial.suggest_int('G', 300, 500)\n  X, ADV, perm = next(m.train_gen.gen_func)\n  x = torch.from_numpy(X).float().to(m.device)\n  m.adv_var['train'].data = torch.tensor(ADV).float().to(m.device)\n  for alpha in np.linspace(1., 0., 7):\n    print('alpha = ', alpha, end=', ')\n    m.alpha = alpha\n    for i in range(G):\n      m.misreport_cycle(x)\n      final_loss, revenue, rgt, u, revenue_excess = m.train_op(x)\n      revenues.append(revenue.detach().cpu().item())\n      rgts.append(rgt.detach().cpu().item())\n      utilitys.append(u.detach().cpu().item())\n      gap.append(revenue_excess)\n\n    print('u={}, rev={}, g={}, rgt={}'.format(utilitys[-1], revenues[-1], gap[-1], rgts[-1]), end = (', ' if alpha == 0. else '\\n'))\n  res = compute_metrics((revenues, rgts, utilitys, gap))\n  return res\n\ndef polynom(x, a, b, c):\n  return a * x ** 2 + b * x + c\n\ndef compute_metrics(logs):\n  revenues, rgts, utilitys, gap = logs\n  gap_mean_abs = np.mean(np.abs(gap))\n  rgts_mean_abs = np.mean(np.abs(rgts))\n  x = np.linspace(1., 0., 20)\n  coefs, _ = curve_fit(polynom, utilitys[:], revenues[:])\n  f = interp1d(utilitys, revenues)\n  x = np.linspace(min(utilitys), max(utilitys), 1000)\n  smoothness = mape(f(x), polynom(f(x), *coefs))\n  u = np.mean(utilitys)\n  res = [-u, gap_mean_abs, rgts_mean_abs, smoothness]\n  return res","metadata":{"id":"XukfNB_KrY2s","execution":{"iopub.status.busy":"2022-06-06T20:18:51.598209Z","iopub.execute_input":"2022-06-06T20:18:51.598684Z","iopub.status.idle":"2022-06-06T20:18:51.636687Z","shell.execute_reply.started":"2022-06-06T20:18:51.598639Z","shell.execute_reply":"2022-06-06T20:18:51.635056Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"study = optuna.create_study(directions=['minimize' for i in range(4)] )\nstudy.optimize(objective, n_trials=300)\n\nprint(\"Number of finished trials: \", len(study.trials))","metadata":{"id":"f7toqp7DuQx8","outputId":"eb5f361c-7830-4d75-aaeb-39b3c8f54789","execution":{"iopub.status.busy":"2022-06-06T20:19:43.301677Z","iopub.execute_input":"2022-06-06T20:19:43.302298Z","iopub.status.idle":"2022-06-06T22:58:40.531609Z","shell.execute_reply.started":"2022-06-06T20:19:43.302262Z","shell.execute_reply":"2022-06-06T22:58:40.530256Z"},"collapsed":true,"jupyter":{"outputs_hidden":true},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def assemble_model(params):\n  device = 'cuda' if torch.cuda.is_available() else 'cpu'\n  checkpoint = torch.load('/kaggle/input/pretrained-rgtdinet/additive_net_3_10.pickle')\n  net2.load_state_dict(checkpoint)\n  num_unfreezed_parameters = params['num_unfreezed_parameters']\n  num_units = params['num_units']\n  num_hidden = params['num_hid']\n  model = WrapperNet(net2, num_unfreezed_parameters, num_units, num_hidden).to(device)\n  cfg.train.revenue_lr = params['revenue_lr']\n  cfg.train.rgt_lr = params['rgt_lr']\n  cfg.train.batch_size = 1024\n  cfg.train.learning_rate = params['learning_rate']\n  cfg.train.w_rgt_val = 42.9537\n  m = Trainer(cfg, model, clip_op_lambda, device)\n  m.revenue_max = 5.61554\n  m.train_gen, m.val_gen = generator\n  return model\n\nfrom tqdm.notebook import trange, tqdm\ndef objective(params):\n  model = assemble_model(params)\n  revenues, utilities, gap, rgts = [], [], [], []\n  G = params['G']\n  X, ADV, perm = next(m.train_gen.gen_func)\n  x = torch.from_numpy(X).float().to(m.device)\n  m.adv_var['train'].data = torch.tensor(ADV).float().to(m.device)\n  for alpha in tqdm(np.linspace(1., 0., 7)):\n    m.alpha = alpha\n    for i in tqdm(range(G)):\n      m.misreport_cycle(x)\n      final_loss, revenue, rgt, u, revenue_excess = m.train_op(x)\n      revenues.append(revenue.detach().cpu().item())\n      rgts.append(rgt.detach().cpu().item())\n      utilities.append(u.detach().cpu().item())\n      gap.append(revenue_excess)\n  res = {'revenue': revenues, 'rgt': rgts, 'utilities': utilities, 'gap': gap]\n  return res","metadata":{"execution":{"iopub.status.busy":"2022-06-06T23:14:49.580423Z","iopub.execute_input":"2022-06-06T23:14:49.580779Z","iopub.status.idle":"2022-06-06T23:14:49.59407Z","shell.execute_reply.started":"2022-06-06T23:14:49.580746Z","shell.execute_reply":"2022-06-06T23:14:49.593175Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"num = study.best_trials[0].number\nresult = objective(study.trials[num].params)\n","metadata":{"execution":{"iopub.status.busy":"2022-06-06T23:40:24.023308Z","iopub.execute_input":"2022-06-06T23:40:24.023664Z","iopub.status.idle":"2022-06-06T23:42:23.807301Z","shell.execute_reply.started":"2022-06-06T23:40:24.023634Z","shell.execute_reply":"2022-06-06T23:42:23.806004Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sns.set(font_scale=1)\nsns.set_theme(color_codes=True)\nfig = plt.figure( figsize=(15, 10))\nplt.plot(result[2], result[0])\nplt.title('Pareto Frontier for 3x10 setting with v_i~U[0, 1]')\nplt.xlabel('Avg. Utility')\nplt.ylabel('Avg. Revenue')","metadata":{"execution":{"iopub.status.busy":"2022-06-06T23:27:33.882286Z","iopub.execute_input":"2022-06-06T23:27:33.882639Z","iopub.status.idle":"2022-06-06T23:27:34.131494Z","shell.execute_reply.started":"2022-06-06T23:27:33.882608Z","shell.execute_reply":"2022-06-06T23:27:34.130767Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"fig, ax = plt.subplots(1, 2, figsize=(30, 10))\nsns.set(font_scale=1.5)\nax[0].plot(result[1])\nax[1].plot(result[3])\nax[0].title.set_text('The dynamics of Regret')\nax[1].title.set_text('The dynamics of a gap between a Current Revenue and a β-fraction of Max. Revenue')\nax[0].set_xlabel('Number of iterations')\nax[1].set_xlabel('Number of iterations')","metadata":{"execution":{"iopub.status.busy":"2022-06-06T23:49:07.116171Z","iopub.execute_input":"2022-06-06T23:49:07.116498Z","iopub.status.idle":"2022-06-06T23:49:07.531707Z","shell.execute_reply.started":"2022-06-06T23:49:07.11647Z","shell.execute_reply":"2022-06-06T23:49:07.530995Z"},"trusted":true},"execution_count":null,"outputs":[]}]}